"use strict";(globalThis.webpackChunkphysical_humanoid_robotics_book=globalThis.webpackChunkphysical_humanoid_robotics_book||[]).push([[71],{446(e,n,a){a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>_,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"modules/module-3/module-3-chapter-3","title":"AI Planning and Navigation with Isaac","description":"This chapter explores how NVIDIA Isaac provides AI-powered planning and navigation capabilities for autonomous robots, with a focus on human-safe navigation for humanoid robots.","source":"@site/content/modules/module-3/chapter-3.md","sourceDirName":"modules/module-3","slug":"/modules/module-3/module-3-chapter-3","permalink":"/docs/modules/module-3/module-3-chapter-3","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-humanoid-robotics/physical-humanoid-robotics-book/tree/main/packages/create-docusaurus/templates/shared/content/modules/module-3/chapter-3.md","tags":[],"version":"current","frontMatter":{"id":"module-3-chapter-3","title":"AI Planning and Navigation with Isaac","sidebar_label":"Isaac Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Perception","permalink":"/docs/modules/module-3/module-3-chapter-2"},"next":{"title":"Isaac Manipulation","permalink":"/docs/modules/module-3/module-3-chapter-4"}}');var s=a(4848),t=a(8453);const i={id:"module-3-chapter-3",title:"AI Planning and Navigation with Isaac",sidebar_label:"Isaac Planning"},l="AI Planning and Navigation with Isaac",r={},c=[{value:"Isaac Navigation System",id:"isaac-navigation-system",level:2},{value:"Isaac Navigation Stack",id:"isaac-navigation-stack",level:2},{value:"Global Planner",id:"global-planner",level:3},{value:"Isaac Local Planner and Obstacle Avoidance",id:"isaac-local-planner-and-obstacle-avoidance",level:2},{value:"DWA Local Planner",id:"dwa-local-planner",level:3},{value:"Human-Aware Navigation",id:"human-aware-navigation",level:2},{value:"Social Navigation with Isaac",id:"social-navigation-with-isaac",level:3},{value:"Isaac SLAM and Mapping",id:"isaac-slam-and-mapping",level:2},{value:"Semantic SLAM",id:"semantic-slam",level:3},{value:"Exercise: Implement Social Navigation",id:"exercise-implement-social-navigation",level:2},{value:"Summary",id:"summary",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ai-planning-and-navigation-with-isaac",children:"AI Planning and Navigation with Isaac"})}),"\n",(0,s.jsx)(n.p,{children:"This chapter explores how NVIDIA Isaac provides AI-powered planning and navigation capabilities for autonomous robots, with a focus on human-safe navigation for humanoid robots."}),"\n",(0,s.jsx)(n.h2,{id:"isaac-navigation-system",children:"Isaac Navigation System"}),"\n",(0,s.jsx)(n.p,{children:"Isaac Navigation includes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Global Path Planning"}),": Long-term route planning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Local Path Planning"}),": Obstacle avoidance and dynamic replanning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Map Building"}),": SLAM and semantic mapping"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Human-Aware Navigation"}),": Navigation that considers human safety and comfort"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"isaac-navigation-stack",children:"Isaac Navigation Stack"}),"\n",(0,s.jsx)(n.h3,{id:"global-planner",children:"Global Planner"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import OccupancyGrid, Path\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom visualization_msgs.msg import Marker\nimport numpy as np\nimport heapq\n\nclass IsaacGlobalPlanner(Node):\n    def __init__(self):\n        super().__init__(\'isaac_global_planner\')\n\n        # Subscriptions\n        self.map_sub = self.create_subscription(\n            OccupancyGrid, \'/map\', self.map_callback, 10\n        )\n        self.goal_sub = self.create_subscription(\n            PoseStamped, \'/move_base_simple/goal\', self.goal_callback, 10\n        )\n\n        # Publishers\n        self.path_pub = self.create_publisher(Path, \'/global_plan\', 10)\n        self.visualization_pub = self.create_publisher(Marker, \'/path_visualization\', 10)\n\n        # Navigation data\n        self.costmap = None\n        self.start_pose = None\n        self.goal_pose = None\n\n    def map_callback(self, msg):\n        """Process occupancy grid map"""\n        self.costmap = np.array(msg.data).reshape((msg.info.height, msg.info.width))\n        self.map_resolution = msg.info.resolution\n        self.map_origin = (msg.info.origin.position.x, msg.info.origin.position.y)\n\n    def goal_callback(self, msg):\n        """Process navigation goal and plan path"""\n        self.goal_pose = msg.pose\n        if self.costmap is not None:\n            path = self.plan_path(self.start_pose, self.goal_pose)\n            self.publish_path(path)\n\n    def plan_path(self, start, goal):\n        """Plan path using A* algorithm with Isaac optimizations"""\n        # Convert world coordinates to map coordinates\n        start_map = self.world_to_map(start.position.x, start.position.y)\n        goal_map = self.world_to_map(goal.position.x, goal.position.y)\n\n        # Implement A* path planning algorithm\n        open_set = [(0, start_map)]\n        came_from = {}\n        g_score = {start_map: 0}\n        f_score = {start_map: self.heuristic(start_map, goal_map)}\n\n        while open_set:\n            current = heapq.heappop(open_set)[1]\n\n            if current == goal_map:\n                # Reconstruct path\n                path = self.reconstruct_path(came_from, current)\n                return self.convert_path_to_ros(path)\n\n            for neighbor in self.get_neighbors(current):\n                if self.is_valid_cell(neighbor):\n                    tentative_g_score = g_score[current] + self.distance(current, neighbor)\n\n                    if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n                        came_from[neighbor] = current\n                        g_score[neighbor] = tentative_g_score\n                        f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, goal_map)\n\n                        heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def heuristic(self, a, b):\n        """Heuristic function for A* (Euclidean distance)"""\n        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\n    def get_neighbors(self, pos):\n        """Get valid neighbors for path planning"""\n        neighbors = []\n        for dx in [-1, 0, 1]:\n            for dy in [-1, 0, 1]:\n                if dx == 0 and dy == 0:\n                    continue\n                neighbors.append((pos[0] + dx, pos[1] + dy))\n        return neighbors\n\n    def is_valid_cell(self, pos):\n        """Check if cell is valid for navigation"""\n        x, y = pos\n        if x < 0 or x >= self.costmap.shape[1] or y < 0 or y >= self.costmap.shape[0]:\n            return False\n        # Check if cell is occupied (value > 50 on 0-100 scale)\n        return self.costmap[y, x] < 50\n\n    def world_to_map(self, x_world, y_world):\n        """Convert world coordinates to map coordinates"""\n        x_map = int((x_world - self.map_origin[0]) / self.map_resolution)\n        y_map = int((y_world - self.map_origin[1]) / self.map_resolution)\n        return (x_map, y_map)\n\n    def convert_path_to_ros(self, path):\n        """Convert path to ROS Path message"""\n        ros_path = Path()\n        ros_path.header.frame_id = "map"\n        ros_path.header.stamp = self.get_clock().now().to_msg()\n\n        for point in path:\n            pose = PoseStamped()\n            pose.header.frame_id = "map"\n            pose.pose.position.x = point[0] * self.map_resolution + self.map_origin[0]\n            pose.pose.position.y = point[1] * self.map_resolution + self.map_origin[1]\n            ros_path.poses.append(pose)\n\n        return ros_path\n'})}),"\n",(0,s.jsx)(n.h2,{id:"isaac-local-planner-and-obstacle-avoidance",children:"Isaac Local Planner and Obstacle Avoidance"}),"\n",(0,s.jsx)(n.h3,{id:"dwa-local-planner",children:"DWA Local Planner"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path\nfrom sensor_msgs.msg import LaserScan, PointCloud2\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom tf2_ros import TransformListener, Buffer\nimport numpy as np\n\nclass IsaacLocalPlanner(Node):\n    def __init__(self):\n        super().__init__(\'isaac_local_planner\')\n\n        # Subscriptions\n        self.global_path_sub = self.create_subscription(\n            Path, \'/global_plan\', self.global_path_callback, 10\n        )\n        self.laser_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.laser_callback, 10\n        )\n        self.odom_sub = self.create_subscription(\n            Odometry, \'/odom\', self.odom_callback, 10\n        )\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.local_plan_pub = self.create_publisher(Path, \'/local_plan\', 10)\n\n        # Robot parameters\n        self.robot_radius = 0.3  # meters\n        self.max_vel_x = 0.5\n        self.max_vel_theta = 1.0\n        self.min_vel_x = 0.1\n        self.min_vel_theta = 0.1\n\n        # Trajectory scoring weights\n        self.goal_cost_weight = 1.0\n        self.obstacle_cost_weight = 1.0\n        self.velocity_cost_weight = 0.1\n\n    def laser_callback(self, msg):\n        """Process laser scan for obstacle detection"""\n        self.laser_ranges = np.array(msg.ranges)\n        self.laser_angle_min = msg.angle_min\n        self.laser_angle_max = msg.angle_max\n        self.laser_angle_increment = msg.angle_increment\n\n    def global_path_callback(self, msg):\n        """Process global path and generate local plan"""\n        self.global_path = msg.poses\n\n    def odom_callback(self, msg):\n        """Process odometry for robot state"""\n        self.robot_pose = msg.pose.pose\n        self.robot_twist = msg.twist.twist\n\n    def generate_trajectory(self, vel_x, vel_theta, time_horizon=1.0, dt=0.1):\n        """Generate trajectory for given velocities"""\n        trajectory = []\n        pose = self.robot_pose\n        time = 0.0\n\n        while time < time_horizon:\n            # Simple motion model\n            new_x = pose.position.x + vel_x * dt * np.cos(pose.orientation.z)\n            new_y = pose.position.y + vel_x * dt * np.sin(pose.orientation.z)\n            new_theta = pose.orientation.z + vel_theta * dt\n\n            # Update pose\n            new_pose = Pose()\n            new_pose.position.x = new_x\n            new_pose.position.y = new_y\n            new_pose.orientation.z = new_theta\n\n            trajectory.append(new_pose)\n            time += dt\n\n        return trajectory\n\n    def score_trajectory(self, trajectory):\n        """Score trajectory based on goal distance, obstacles, and velocity"""\n        # Goal distance cost\n        if len(trajectory) > 0:\n            final_pose = trajectory[-1]\n            goal_dist = self.distance_to_goal(final_pose)\n            goal_cost = goal_dist\n        else:\n            goal_cost = float(\'inf\')\n\n        # Obstacle cost\n        obstacle_cost = 0\n        for pose in trajectory:\n            if self.is_in_collision(pose):\n                obstacle_cost = float(\'inf\')\n                break\n            # Add cost based on proximity to obstacles\n            min_dist = self.min_distance_to_obstacles(pose)\n            if min_dist < 0.5:  # 0.5m safety margin\n                obstacle_cost += (0.5 - min_dist) * 10\n\n        # Velocity cost (prefer higher velocities)\n        velocity_cost = -(self.max_vel_x - self.current_vel_x) * self.velocity_cost_weight\n\n        total_cost = (self.goal_cost_weight * goal_cost +\n                     self.obstacle_cost_weight * obstacle_cost +\n                     velocity_cost)\n\n        return total_cost\n\n    def is_in_collision(self, pose):\n        """Check if pose is in collision with obstacles"""\n        # Check laser ranges for collision at this pose\n        robot_x = pose.position.x\n        robot_y = pose.position.y\n\n        # Transform laser points to map frame and check collision\n        for i, range_val in enumerate(self.laser_ranges):\n            if not np.isfinite(range_val):\n                continue\n            angle = self.laser_angle_min + i * self.laser_angle_increment\n            point_x = robot_x + range_val * np.cos(angle)\n            point_y = robot_y + range_val * np.sin(angle)\n\n            # Check distance to this obstacle point\n            dist = np.sqrt((point_x - robot_x)**2 + (point_y - robot_y)**2)\n            if dist < self.robot_radius:\n                return True\n\n        return False\n\n    def control_loop(self):\n        """Main control loop for local planning"""\n        # Generate possible trajectories\n        trajectories = []\n        for vel_x in np.linspace(self.min_vel_x, self.max_vel_x, 5):\n            for vel_theta in np.linspace(-self.max_vel_theta, self.max_vel_theta, 7):\n                trajectory = self.generate_trajectory(vel_x, vel_theta)\n                score = self.score_trajectory(trajectory)\n                trajectories.append((trajectory, score, (vel_x, vel_theta)))\n\n        # Select best trajectory\n        best_trajectory = min(trajectories, key=lambda x: x[1])\n        best_vel_x, best_vel_theta = best_trajectory[2]\n\n        # Publish velocity command\n        cmd_vel = Twist()\n        cmd_vel.linear.x = best_vel_x\n        cmd_vel.angular.z = best_vel_theta\n        self.cmd_vel_pub.publish(cmd_vel)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"human-aware-navigation",children:"Human-Aware Navigation"}),"\n",(0,s.jsx)(n.h3,{id:"social-navigation-with-isaac",children:"Social Navigation with Isaac"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom people_msgs.msg import People, Person\nfrom visualization_msgs.msg import MarkerArray\nimport numpy as np\n\nclass IsaacSocialNavigation(Node):\n    def __init__(self):\n        super().__init__(\'isaac_social_navigation\')\n\n        # Subscriptions\n        self.people_sub = self.create_subscription(\n            People, \'/people\', self.people_callback, 10\n        )\n        self.goal_sub = self.create_subscription(\n            PoseStamped, \'/move_base_simple/goal\', self.goal_callback, 10\n        )\n\n        # Publishers\n        self.social_cmd_pub = self.create_publisher(Twist, \'/social_cmd_vel\', 10)\n        self.visualization_pub = self.create_publisher(MarkerArray, \'/social_visualization\', 10)\n\n        # Social navigation parameters\n        self.personal_space_radius = 0.8  # meters\n        self.comfort_zone_radius = 1.2   # meters\n        self.respectful_distance = 1.5   # meters\n\n    def people_callback(self, msg):\n        """Process detected people for social navigation"""\n        self.people_list = msg.people\n        self.update_social_navigation()\n\n    def update_social_navigation(self):\n        """Update navigation based on people detection"""\n        if not self.people_list:\n            return\n\n        # Calculate social forces\n        repulsion_force = np.array([0.0, 0.0])\n        attraction_force = np.array([0.0, 0.0])\n\n        for person in self.people_list:\n            person_pos = np.array([person.position.x, person.position.y])\n            robot_pos = np.array([self.robot_pose.position.x, self.robot_pose.position.y])\n\n            # Calculate distance to person\n            distance = np.linalg.norm(person_pos - robot_pos)\n\n            if distance < self.comfort_zone_radius:\n                # Apply repulsion force to maintain personal space\n                direction = robot_pos - person_pos\n                direction = direction / np.linalg.norm(direction)  # normalize\n                strength = (self.comfort_zone_radius - distance) / self.comfort_zone_radius\n                repulsion_force += direction * strength\n\n        # Combine with goal-seeking behavior\n        goal_direction = self.calculate_goal_direction()\n        combined_force = 0.7 * goal_direction + 0.3 * repulsion_force\n\n        # Normalize and convert to velocity command\n        if np.linalg.norm(combined_force) > 0:\n            normalized_force = combined_force / np.linalg.norm(combined_force)\n            self.publish_social_command(normalized_force)\n\n    def calculate_goal_direction(self):\n        """Calculate direction towards navigation goal"""\n        if self.goal_pose:\n            goal_vec = np.array([self.goal_pose.position.x - self.robot_pose.position.x,\n                               self.goal_pose.position.y - self.robot_pose.position.y])\n            if np.linalg.norm(goal_vec) > 0:\n                return goal_vec / np.linalg.norm(goal_vec)\n        return np.array([0.0, 0.0])\n\n    def publish_social_command(self, direction):\n        """Publish social navigation command"""\n        cmd_vel = Twist()\n        cmd_vel.linear.x = min(0.3, np.linalg.norm(direction) * 0.5)  # Speed limit\n        cmd_vel.angular.z = np.arctan2(direction[1], direction[0]) * 0.5  # Turn towards direction\n        self.social_cmd_pub.publish(cmd_vel)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"isaac-slam-and-mapping",children:"Isaac SLAM and Mapping"}),"\n",(0,s.jsx)(n.h3,{id:"semantic-slam",children:"Semantic SLAM"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, PointCloud2\nfrom nav_msgs.msg import OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped\nfrom isaac_ros_visual_slam_interfaces.msg import VisualSlamStatus\nimport numpy as np\n\nclass IsaacSemanticSLAM(Node):\n    def __init__(self):\n        super().__init__(\'isaac_semantic_slam\')\n\n        # Subscriptions\n        self.rgb_sub = self.create_subscription(\n            Image, \'/camera/rgb/image_rect_color\', self.rgb_callback, 10\n        )\n        self.depth_sub = self.create_subscription(\n            Image, \'/camera/depth/image_rect_raw\', self.depth_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10\n        )\n\n        # Publishers\n        self.map_pub = self.create_publisher(OccupancyGrid, \'/semantic_map\', 10)\n        self.pose_pub = self.create_publisher(PoseStamped, \'/slam_pose\', 10)\n\n        # SLAM data\n        self.keyframes = []\n        self.semantic_annotations = {}\n        self.current_pose = None\n\n    def rgb_callback(self, msg):\n        """Process RGB image for visual SLAM"""\n        # Extract features and match with previous frames\n        features = self.extract_features(msg)\n        self.process_visual_odometry(features, msg.header.stamp)\n\n    def depth_callback(self, msg):\n        """Process depth image for 3D reconstruction"""\n        # Combine with RGB for semantic mapping\n        if self.current_pose:\n            self.update_3d_map(msg, self.current_pose)\n\n    def process_visual_odometry(self, features, timestamp):\n        """Process visual odometry for pose estimation"""\n        # Match features with previous keyframes\n        # Estimate camera motion\n        # Update robot pose\n        pass\n\n    def update_3d_map(self, depth_msg, pose):\n        """Update 3D semantic map with new observations"""\n        # Convert depth image to 3D points in robot frame\n        # Transform to global map frame using pose\n        # Integrate into occupancy grid\n        # Add semantic labels from perception system\n        pass\n\n    def integrate_semantic_labels(self, segmentation_result, pose):\n        """Integrate semantic segmentation results into map"""\n        # Project segmentation onto 3D map\n        # Update semantic labels for map regions\n        # Handle label conflicts and uncertainties\n        pass\n'})}),"\n",(0,s.jsx)(n.h2,{id:"exercise-implement-social-navigation",children:"Exercise: Implement Social Navigation"}),"\n",(0,s.jsx)(n.p,{children:"Create a navigation system that:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Detects people in the environment"}),"\n",(0,s.jsx)(n.li,{children:"Plans paths that respect personal space"}),"\n",(0,s.jsx)(n.li,{children:"Adjusts speed and behavior based on social context"}),"\n",(0,s.jsx)(n.li,{children:"Visualizes social navigation decisions"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Isaac provides comprehensive AI planning and navigation capabilities that enable robots to move safely and efficiently in human environments. The combination of global planning, local obstacle avoidance, and social navigation makes it possible to create robots that can navigate complex environments while respecting human comfort and safety."}),"\n",(0,s.jsx)(n.hr,{})]})}function _(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},8453(e,n,a){a.d(n,{R:()=>i,x:()=>l});var o=a(6540);const s={},t=o.createContext(s);function i(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);