"use strict";(globalThis.webpackChunkphysical_humanoid_robotics_book=globalThis.webpackChunkphysical_humanoid_robotics_book||[]).push([[150],{2124(e){e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/ur/docs/chapters/intro","label":"Introduction","docId":"chapters/intro","unlisted":false},{"type":"link","href":"/ur/docs/introduction","label":"Introduction","docId":"introduction","unlisted":false},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"category","label":"Chapter 1: Introduction to ROS 2 for Humanoids","items":[{"type":"link","href":"/ur/docs/modules/module-1/module-1-chapter-1","label":"ROS 2 Basics","docId":"modules/module-1/module-1-chapter-1","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: ROS 2 Communication Patterns","items":[{"type":"link","href":"/ur/docs/modules/module-1/module-1-chapter-2","label":"ROS 2 Patterns","docId":"modules/module-1/module-1-chapter-2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: ROS 2 Navigation and Control","items":[{"type":"link","href":"/ur/docs/modules/module-1/module-1-chapter-3","label":"Humanoid Control","docId":"modules/module-1/module-1-chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: ROS 2 Perception and Sensing","items":[{"type":"link","href":"/ur/docs/modules/module-1/module-1-chapter-4","label":"Humanoid Packages","docId":"modules/module-1/module-1-chapter-4","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 5: ROS 2 Integration and Testing","items":[{"type":"link","href":"/ur/docs/modules/module-1/module-1-chapter-5","label":"Best Practices","docId":"modules/module-1/module-1-chapter-5","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin (Gazebo & Unity)","items":[{"type":"category","label":"Chapter 1: Digital Twin Fundamentals","items":[{"type":"link","href":"/ur/docs/modules/module-2/module-2-chapter-1","label":"Digital Twin Basics","docId":"modules/module-2/module-2-chapter-1","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: Gazebo Simulation for Humanoids","items":[{"type":"link","href":"/ur/docs/modules/module-2/module-2-chapter-2","label":"Gazebo Simulation","docId":"modules/module-2/module-2-chapter-2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: Unity Integration and VR","items":[{"type":"link","href":"/ur/docs/modules/module-2/module-2-chapter-3","label":"Unity Simulation","docId":"modules/module-2/module-2-chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: Simulation to Reality Transfer","items":[{"type":"link","href":"/ur/docs/modules/module-2/module-2-chapter-4","label":"Sim-to-Real Transfer","docId":"modules/module-2/module-2-chapter-4","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 5: Digital Twin Validation","items":[{"type":"link","href":"/ur/docs/modules/module-2/module-2-chapter-5","label":"Digital Twin Integration","docId":"modules/module-2/module-2-chapter-5","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI-Brain (NVIDIA Isaac)","items":[{"type":"category","label":"Chapter 1: Introduction to NVIDIA Isaac for Robotics","items":[{"type":"link","href":"/ur/docs/modules/module-3/module-3-chapter-1","label":"Isaac AI Basics","docId":"modules/module-3/module-3-chapter-1","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: Isaac Perception and Understanding","items":[{"type":"link","href":"/ur/docs/modules/module-3/module-3-chapter-2","label":"Isaac Perception","docId":"modules/module-3/module-3-chapter-2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: Isaac AI Planning and Navigation","items":[{"type":"link","href":"/ur/docs/modules/module-3/module-3-chapter-3","label":"Isaac Planning","docId":"modules/module-3/module-3-chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: Isaac Manipulation and Control","items":[{"type":"link","href":"/ur/docs/modules/module-3/module-3-chapter-4","label":"Isaac Manipulation","docId":"modules/module-3/module-3-chapter-4","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 5: Isaac Learning and Adaptation","items":[{"type":"link","href":"/ur/docs/modules/module-3/module-3-chapter-5","label":"Isaac Learning","docId":"modules/module-3/module-3-chapter-5","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"category","label":"Chapter 1: Introduction to Vision-Language-Action Systems","items":[{"type":"link","href":"/ur/docs/modules/module-4/module-4-chapter-1","label":"VLA Basics","docId":"modules/module-4/module-4-chapter-1","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: Implementing Vision-Language Models for Robotics","items":[{"type":"link","href":"/ur/docs/modules/module-4/module-4-chapter-2","label":"VLA Implementation","docId":"modules/module-4/module-4-chapter-2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: AI Perception and Decision Making","items":[{"type":"link","href":"/ur/docs/modules/module-4/module-4-chapter-3","label":"VLA Actions","docId":"modules/module-4/module-4-chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: Humanoid Robot Integration and Testing","items":[{"type":"link","href":"/ur/docs/modules/module-4/module-4-chapter-4","label":"VLA Training","docId":"modules/module-4/module-4-chapter-4","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 5: Deploying VLA Systems in Real-World Robotics","items":[{"type":"link","href":"/ur/docs/modules/module-4/module-4-chapter-5","label":"VLA Deployment","docId":"modules/module-4/module-4-chapter-5","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 5: Capstone - Autonomous Humanoid Project","items":[{"type":"category","label":"Chapter 1: Autonomous Humanoid Project Overview","items":[{"type":"link","href":"/ur/docs/modules/module-5/module-5-chapter-1","label":"Project Overview","docId":"modules/module-5/module-5-chapter-1","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: Humanoid Robot Control Systems","items":[{"type":"link","href":"/ur/docs/modules/module-5/module-5-chapter-2","label":"Control Systems","docId":"modules/module-5/module-5-chapter-2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: [To be created]","items":[{"type":"link","href":"/ur/docs/modules/module-5/module-5-chapter-3","label":"AI Perception","docId":"modules/module-5/module-5-chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: [To be created]","items":[{"type":"link","href":"/ur/docs/modules/module-5/module-5-chapter-4","label":"Integration & Testing","docId":"modules/module-5/module-5-chapter-4","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 5: Complete Humanoid Robot System Integration","items":[{"type":"link","href":"/ur/docs/modules/module-5/module-5-chapter-5","label":"Capstone Project","docId":"modules/module-5/module-5-chapter-5","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","href":"/ur/docs/conclusion","label":"Conclusion","docId":"conclusion","unlisted":false}]},"docs":{"chapters/intro":{"id":"chapters/intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the interactive book on Physical AI and Humanoid Robotics. This book explores the fascinating intersection of artificial intelligence and embodied systems, where digital intelligence meets the physical world.","sidebar":"tutorialSidebar"},"conclusion":{"id":"conclusion","title":"Conclusion & Next Steps","description":"Congratulations on completing the Physical AI & Humanoid Robotics Interactive Book! You now have a comprehensive understanding of building autonomous humanoid robots using state-of-the-art technologies.","sidebar":"tutorialSidebar"},"introduction":{"id":"introduction","title":"Physical AI & Humanoid Robotics Interactive Book","description":"Welcome to the comprehensive guide on Physical AI and Humanoid Robotics! This interactive book provides a complete educational journey through the cutting-edge field of autonomous humanoid robots, combining theoretical knowledge with practical implementation.","sidebar":"tutorialSidebar"},"modules/module-1/module-1-chapter-1":{"id":"modules/module-1/module-1-chapter-1","title":"Introduction to ROS 2: The Foundation of Robotic Communication","description":"Welcome to Module 1: The Robotic Nervous System (ROS 2). This module will introduce you to the Robot Operating System (ROS 2), which serves as the communication backbone for modern robotics applications.","sidebar":"tutorialSidebar"},"modules/module-1/module-1-chapter-2":{"id":"modules/module-1/module-1-chapter-2","title":"Advanced ROS 2 Communication Patterns","description":"In this chapter, we\'ll explore advanced communication patterns in ROS 2 that are essential for building complex robotic systems.","sidebar":"tutorialSidebar"},"modules/module-1/module-1-chapter-3":{"id":"modules/module-1/module-1-chapter-3","title":"ROS 2 for Humanoid Robot Control","description":"This chapter focuses on applying ROS 2 concepts specifically to humanoid robot control systems, which require precise coordination of multiple joints and sensors.","sidebar":"tutorialSidebar"},"modules/module-1/module-1-chapter-4":{"id":"modules/module-1/module-1-chapter-4","title":"ROS 2 Packages for Humanoid Robots","description":"This chapter covers specialized ROS 2 packages and tools specifically designed for humanoid robot development and control.","sidebar":"tutorialSidebar"},"modules/module-1/module-1-chapter-5":{"id":"modules/module-1/module-1-chapter-5","title":"ROS 2 Best Practices for Humanoid Systems","description":"This chapter covers best practices and design patterns specifically for humanoid robot systems using ROS 2.","sidebar":"tutorialSidebar"},"modules/module-2/module-2-chapter-1":{"id":"modules/module-2/module-2-chapter-1","title":"Introduction to Digital Twins in Robotics","description":"Welcome to Module 2: The Digital Twin (Gazebo & Unity). This module explores the concept of digital twins in robotics and how simulation environments enable the development and testing of complex robotic systems.","sidebar":"tutorialSidebar"},"modules/module-2/module-2-chapter-2":{"id":"modules/module-2/module-2-chapter-2","title":"Gazebo: Physics-Based Simulation for Robotics","description":"Gazebo is a powerful physics-based simulation environment that provides realistic robot simulation capabilities essential for humanoid robot development.","sidebar":"tutorialSidebar"},"modules/module-2/module-2-chapter-3":{"id":"modules/module-2/module-2-chapter-3","title":"Unity: High-Fidelity Visualization and Simulation","description":"Unity provides high-fidelity visualization and simulation capabilities that complement physics-based simulators like Gazebo, offering photorealistic rendering and advanced graphics features.","sidebar":"tutorialSidebar"},"modules/module-2/module-2-chapter-4":{"id":"modules/module-2/module-2-chapter-4","title":"Simulation to Reality Transfer (Sim-to-Real)","description":"Sim-to-real transfer is the process of taking behaviors, controllers, or learned policies from simulation and successfully deploying them on real robots. This is a critical challenge in robotics.","sidebar":"tutorialSidebar"},"modules/module-2/module-2-chapter-5":{"id":"modules/module-2/module-2-chapter-5","title":"Digital Twin Integration with ROS 2","description":"This chapter explores how to integrate digital twin systems with ROS 2, creating a seamless connection between simulation and real-world robotics applications.","sidebar":"tutorialSidebar"},"modules/module-3/module-3-chapter-1":{"id":"modules/module-3/module-3-chapter-1","title":"Introduction to NVIDIA Isaac ROS and AI Robotics","description":"Welcome to Module 3: The AI-Robot Brain (NVIDIA Isaac). This module explores how NVIDIA Isaac provides the AI capabilities that power modern robotics, with a focus on perception, planning, and control.","sidebar":"tutorialSidebar"},"modules/module-3/module-3-chapter-2":{"id":"modules/module-3/module-3-chapter-2","title":"Isaac ROS Perception Pipeline","description":"This chapter explores the perception capabilities of NVIDIA Isaac ROS, focusing on how AI-powered perception systems enable robots to understand their environment.","sidebar":"tutorialSidebar"},"modules/module-3/module-3-chapter-3":{"id":"modules/module-3/module-3-chapter-3","title":"AI Planning and Navigation with Isaac","description":"This chapter explores how NVIDIA Isaac provides AI-powered planning and navigation capabilities for autonomous robots, with a focus on human-safe navigation for humanoid robots.","sidebar":"tutorialSidebar"},"modules/module-3/module-3-chapter-4":{"id":"modules/module-3/module-3-chapter-4","title":"Isaac Manipulation and Control","description":"This chapter explores how NVIDIA Isaac enables sophisticated manipulation and control capabilities for robotic systems, particularly relevant for humanoid robots with complex manipulation requirements.","sidebar":"tutorialSidebar"},"modules/module-3/module-3-chapter-5":{"id":"modules/module-3/module-3-chapter-5","title":"Isaac AI Brain: Learning and Adaptation","description":"This chapter explores how NVIDIA Isaac enables machine learning and adaptation capabilities that allow robots to learn from experience and adapt to new situations.","sidebar":"tutorialSidebar"},"modules/module-4/module-4-chapter-1":{"id":"modules/module-4/module-4-chapter-1","title":"Introduction to Vision-Language-Action (VLA) Systems","description":"Welcome to Module 4: Vision-Language-Action (VLA). This module explores how modern AI systems integrate visual perception, language understanding, and physical action to create intelligent robotic systems capable of complex human-robot interaction.","sidebar":"tutorialSidebar"},"modules/module-4/module-4-chapter-2":{"id":"modules/module-4/module-4-chapter-2","title":"Implementing Vision-Language Models for Robotics","description":"This chapter focuses on practical implementation of vision-language models specifically tailored for robotic applications, with emphasis on real-time performance and embodied intelligence.","sidebar":"tutorialSidebar"},"modules/module-4/module-4-chapter-3":{"id":"modules/module-4/module-4-chapter-3","title":"Action Generation and Execution in VLA Systems","description":"This chapter explores how Vision-Language-Action (VLA) systems generate and execute physical actions based on multimodal input, bridging the gap between perception and action in robotic systems.","sidebar":"tutorialSidebar"},"modules/module-4/module-4-chapter-4":{"id":"modules/module-4/module-4-chapter-4","title":"Training VLA Models for Robotic Applications","description":"This chapter explores the methodologies and techniques for training Vision-Language-Action (VLA) models specifically for robotic applications, covering data collection, model architectures, and training strategies.","sidebar":"tutorialSidebar"},"modules/module-4/module-4-chapter-5":{"id":"modules/module-4/module-4-chapter-5","title":"Deploying VLA Systems in Real-World Robotics","description":"This chapter covers the practical aspects of deploying Vision-Language-Action (VLA) systems in real-world robotic applications, focusing on optimization, integration, and deployment considerations.","sidebar":"tutorialSidebar"},"modules/module-5/module-5-chapter-1":{"id":"modules/module-5/module-5-chapter-1","title":"Autonomous Humanoid Project Overview","description":"Welcome to Module 5: Capstone - Autonomous Humanoid Project. This capstone module integrates all previous modules to create a comprehensive autonomous humanoid robot system capable of complex tasks through multimodal perception, AI-driven decision making, and precise control.","sidebar":"tutorialSidebar"},"modules/module-5/module-5-chapter-2":{"id":"modules/module-5/module-5-chapter-2","title":"Humanoid Robot Control Systems","description":"This chapter delves into the control systems that enable precise and stable movement of the humanoid robot, including whole-body control, balance maintenance, and coordinated motion planning.","sidebar":"tutorialSidebar"},"modules/module-5/module-5-chapter-3":{"id":"modules/module-5/module-5-chapter-3","title":"AI Perception and Decision Making","description":"This chapter explores the AI systems that enable the humanoid robot to perceive its environment, understand complex situations, and make intelligent decisions based on multimodal input.","sidebar":"tutorialSidebar"},"modules/module-5/module-5-chapter-4":{"id":"modules/module-5/module-5-chapter-4","title":"Humanoid Robot Integration and Testing","description":"This chapter covers the integration of all subsystems into a complete humanoid robot system and the comprehensive testing required to ensure reliable operation.","sidebar":"tutorialSidebar"},"modules/module-5/module-5-chapter-5":{"id":"modules/module-5/module-5-chapter-5","title":"Capstone Project: Complete Humanoid Robot System","description":"This capstone chapter integrates all components developed throughout the course into a complete, functional humanoid robot system. This represents the culmination of all previous modules, combining the robotic nervous system, digital twin, AI brain, and vision-language-action capabilities into a unified autonomous platform.","sidebar":"tutorialSidebar"}}}}')}}]);