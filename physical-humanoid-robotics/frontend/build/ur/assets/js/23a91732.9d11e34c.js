"use strict";(globalThis.webpackChunkphysical_humanoid_robotics_book=globalThis.webpackChunkphysical_humanoid_robotics_book||[]).push([[7],{1329(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"modules/module-2/module-2-chapter-3","title":"Unity: High-Fidelity Visualization and Simulation","description":"Unity provides high-fidelity visualization and simulation capabilities that complement physics-based simulators like Gazebo, offering photorealistic rendering and advanced graphics features.","source":"@site/content/modules/module-2/chapter-3.md","sourceDirName":"modules/module-2","slug":"/modules/module-2/module-2-chapter-3","permalink":"/ur/docs/modules/module-2/module-2-chapter-3","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-humanoid-robotics/physical-humanoid-robotics-book/tree/main/packages/create-docusaurus/templates/shared/content/modules/module-2/chapter-3.md","tags":[],"version":"current","frontMatter":{"id":"module-2-chapter-3","title":"Unity: High-Fidelity Visualization and Simulation","sidebar_label":"Unity Simulation"},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Simulation","permalink":"/ur/docs/modules/module-2/module-2-chapter-2"},"next":{"title":"Sim-to-Real Transfer","permalink":"/ur/docs/modules/module-2/module-2-chapter-4"}}');var o=t(4848),r=t(8453);const s={id:"module-2-chapter-3",title:"Unity: High-Fidelity Visualization and Simulation",sidebar_label:"Unity Simulation"},a="Unity: High-Fidelity Visualization and Simulation",l={},c=[{value:"Unity for Robotics Overview",id:"unity-for-robotics-overview",level:2},{value:"Unity Robotics Hub",id:"unity-robotics-hub",level:2},{value:"Setting up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Installation",id:"installation",level:3},{value:"ROS-TCP-Connector Setup",id:"ros-tcp-connector-setup",level:3},{value:"Unity Perception Package",id:"unity-perception-package",level:2},{value:"ML-Agents for Robot Learning",id:"ml-agents-for-robot-learning",level:2},{value:"Exercise: Create a Simple Unity Robot Controller",id:"exercise-create-a-simple-unity-robot-controller",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"unity-high-fidelity-visualization-and-simulation",children:"Unity: High-Fidelity Visualization and Simulation"})}),"\n",(0,o.jsx)(e.p,{children:"Unity provides high-fidelity visualization and simulation capabilities that complement physics-based simulators like Gazebo, offering photorealistic rendering and advanced graphics features."}),"\n",(0,o.jsx)(e.h2,{id:"unity-for-robotics-overview",children:"Unity for Robotics Overview"}),"\n",(0,o.jsx)(e.p,{children:"Unity Robotics provides:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Photorealistic Rendering"}),": High-quality visuals for realistic perception simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"XR Support"}),": Virtual and augmented reality capabilities"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Asset Store"}),": Extensive library of 3D models and environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"C# Scripting"}),": Alternative to C++/Python for robotics applications"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cross-Platform"}),": Deploy to multiple platforms including mobile and VR"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"unity-robotics-hub",children:"Unity Robotics Hub"}),"\n",(0,o.jsx)(e.p,{children:"The Unity Robotics Hub provides essential tools:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": Bridge between Unity and ROS/ROS2"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Perception"}),": Tools for synthetic data generation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ML-Agents"}),": Reinforcement learning framework"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Visual Scripting"}),": No-code development tools"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"setting-up-unity-for-robotics",children:"Setting up Unity for Robotics"}),"\n",(0,o.jsx)(e.h3,{id:"installation",children:"Installation"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Download Unity Hub from unity.com"}),"\n",(0,o.jsx)(e.li,{children:"Install Unity 2022.3 LTS or newer"}),"\n",(0,o.jsx)(e.li,{children:"Install required packages via Unity Package Manager"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"ros-tcp-connector-setup",children:"ROS-TCP-Connector Setup"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example Unity C# script for ROS communication\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing Unity.Robotics.ROSTCPConnector.MessageTypes.Sensor;\n\npublic class RobotController : MonoBehaviour\n{\n    ROSConnection ros;\n    string rosIP = "127.0.0.1";\n    int rosPort = 10000;\n\n    // Robot joint angles\n    float[] jointAngles = new float[18];\n\n    void Start()\n    {\n        // Connect to ROS\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Initialize(rosIP, rosPort);\n\n        // Start publishing joint states\n        InvokeRepeating("PublishJointStates", 0.0f, 0.05f); // 20 Hz\n    }\n\n    void PublishJointStates()\n    {\n        // Update joint angles (example with simple oscillation)\n        for (int i = 0; i < jointAngles.Length; i++)\n        {\n            jointAngles[i] = Mathf.Sin(Time.time + i * 0.5f) * 0.5f;\n        }\n\n        // Create and publish joint state message\n        var jointState = new JointStateMsg();\n        jointState.name = new string[] {\n            "left_hip_yaw", "left_hip_roll", "left_hip_pitch",\n            "left_knee", "left_ankle_pitch", "left_ankle_roll",\n            "right_hip_yaw", "right_hip_roll", "right_hip_pitch",\n            "right_knee", "right_ankle_pitch", "right_ankle_roll",\n            "left_shoulder_pitch", "left_shoulder_roll", "left_elbow",\n            "right_shoulder_pitch", "right_shoulder_roll", "right_elbow"\n        };\n        jointState.position = jointAngles;\n        jointState.velocity = new float[jointAngles.Length];\n        jointState.effort = new float[jointAngles.Length];\n\n        ros.Publish("/joint_states", jointState);\n    }\n\n    void OnJointStateMessage(JointStateMsg jointState)\n    {\n        // Process incoming joint state messages\n        for (int i = 0; i < jointState.name.Length; i++)\n        {\n            // Update robot model based on joint positions\n            UpdateJoint(jointState.name[i], jointState.position[i]);\n        }\n    }\n\n    void UpdateJoint(string jointName, float angle)\n    {\n        // Find the joint in the hierarchy and rotate it\n        Transform joint = transform.Find(jointName);\n        if (joint != null)\n        {\n            // Apply rotation based on joint type\n            joint.localRotation = Quaternion.Euler(0, angle * Mathf.Rad2Deg, 0);\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"unity-perception-package",children:"Unity Perception Package"}),"\n",(0,o.jsx)(e.p,{children:"Unity Perception enables synthetic data generation for AI training:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:"using Unity.Perception.GroundTruth;\nusing Unity.Perception.Labeling;\n\npublic class PerceptionSetup : MonoBehaviour\n{\n    void Start()\n    {\n        // Register the dataset capture component\n        var datasetCapture = gameObject.AddComponent<DatasetCapture>();\n\n        // Configure capture settings\n        datasetCapture.CaptureSegmentationLabels = true;\n        datasetCapture.CaptureDepth = true;\n        datasetCapture.CaptureOcclusion = true;\n\n        // Set up semantic segmentation\n        var semanticSegmentation = gameObject.AddComponent<SemanticSegmentationLabeler>();\n    }\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"ml-agents-for-robot-learning",children:"ML-Agents for Robot Learning"}),"\n",(0,o.jsx)(e.p,{children:"Unity ML-Agents enables reinforcement learning for humanoid robots:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using Unity.MLAgents;\nusing Unity.MLAgents.Sensors;\nusing Unity.MLAgents.Actuators;\n\npublic class HumanoidAgent : Agent\n{\n    [SerializeField] Transform target;\n    [SerializeField] float moveSpeed = 5f;\n    [SerializeField] float rotationSpeed = 100f;\n\n    Rigidbody rb;\n\n    void Start()\n    {\n        rb = GetComponent<Rigidbody>();\n    }\n\n    public override void OnEpisodeBegin()\n    {\n        // Reset agent position\n        transform.position = new Vector3(Random.Range(-5f, 5f), 1f, Random.Range(-5f, 5f));\n        rb.velocity = Vector3.zero;\n        rb.angularVelocity = Vector3.zero;\n    }\n\n    public override void CollectObservations(VectorSensor sensor)\n    {\n        // Agent position and rotation\n        sensor.AddObservation(transform.position);\n        sensor.AddObservation(transform.rotation);\n\n        // Target position\n        sensor.AddObservation(target.position);\n\n        // Velocity\n        sensor.AddObservation(rb.velocity);\n    }\n\n    public override void OnActionReceived(ActionBuffers actions)\n    {\n        // Extract actions\n        float moveX = actions.ContinuousActions[0];\n        float moveZ = actions.ContinuousActions[1];\n        float rotation = actions.ContinuousActions[2];\n\n        // Apply movement\n        Vector3 moveDirection = new Vector3(moveX, 0, moveZ).normalized;\n        rb.AddForce(moveDirection * moveSpeed, ForceMode.Acceleration);\n        transform.Rotate(Vector3.up, rotation * rotationSpeed * Time.deltaTime);\n\n        // Reward system\n        float distanceToTarget = Vector3.Distance(transform.position, target.position);\n        SetReward(-distanceToTarget * 0.01f); // Negative reward for distance\n\n        // End episode if close to target\n        if (distanceToTarget < 1.5f)\n        {\n            SetReward(1f);\n            EndEpisode();\n        }\n    }\n\n    public override void Heuristic(in ActionBuffers actionsOut)\n    {\n        var continuousActionsOut = actionsOut.ContinuousActions;\n        continuousActionsOut[0] = Input.GetAxis("Horizontal");\n        continuousActionsOut[1] = Input.GetAxis("Vertical");\n        continuousActionsOut[2] = Input.GetAxis("Rotate");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"exercise-create-a-simple-unity-robot-controller",children:"Exercise: Create a Simple Unity Robot Controller"}),"\n",(0,o.jsx)(e.p,{children:"Create a Unity scene with:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"A simple humanoid robot model"}),"\n",(0,o.jsx)(e.li,{children:"Joint control system"}),"\n",(0,o.jsx)(e.li,{children:"Basic ROS communication"}),"\n",(0,o.jsx)(e.li,{children:"Perception components for data collection"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Unity provides high-fidelity visualization and simulation capabilities that complement physics-based simulators. Its photorealistic rendering, XR support, and machine learning frameworks make it valuable for perception system development and AI training in robotics applications."}),"\n",(0,o.jsx)(e.hr,{})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453(n,e,t){t.d(e,{R:()=>s,x:()=>a});var i=t(6540);const o={},r=i.createContext(o);function s(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);